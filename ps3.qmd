---
title: "STATS 506 - Problem set 3"
author: "Mina Dao"
format: html
editor: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading Packages

```{r, warning = FALSE, message = FALSE}
library(dplyr)
library(ggplot2)
library(GGally)
library(microbenchmark)
library(tidyr)
library(haven)
library(broom)
library(kableExtra)
library(RSQLite)
library(DBI)
library(benford.analysis)
```

## Problem 1:

#### a. Merge two datasets into a single `data.frame` and print out the dimensions

```{r}
aux <- read_xpt("AUX_I.xpt")
demo <- read_xpt("DEMO_I.xpt")

df <- inner_join(demo, aux, by = "SEQN")
head(df)
dim(df)
```

#### b. Clean the data

* Gender

```{r}
# We do not have any missing values => convert to factor
df <- df %>% 
  mutate(
    Gender = factor(RIAGENDR,
                    levels = c(1, 2),
                    labels = c("M", "F"))
)
head(df["Gender"])
```


* Citizenship status

```{r}
# convert "refused" and "don't know" to NA values
# recode the column into factor
df <- df %>% 
  mutate(
    DMDCITZN = ifelse(DMDCITZN %in% c(7, 9), NA, DMDCITZN),
    Citizenship = factor(DMDCITZN,
                         levels = c(1, 2),
                         labels = c("Citizen",  "Non-Citizen"))
  )

unique(df["Citizenship"])
```

* Number of children 5 years or younger in the household
```{r}
# no missing values so recode
df <- df %>% 
  mutate(
    Children_under_5 = factor(DMDHHSZA,
                              levels = c(0, 1, 2, 3),
                              labels = c("0", "1", "2", "3 or more"))
  )

unique(df["Children_under_5"])
```

* Annual household income

We can see in the description file of `DEMO_I.xpt` that the variable is categorical but unordered, value `11` is missing, and the levels are not numerical sorted.

```{r}
# create an ordered factor 
income_levels <- c("$0 - $4,999",
                   "$5,000 – $9,999",
                   "$10,000 – $14,999",
                   "$15,000 – $19,999",
                   "$20,000 – $24,999",
                   "$25,000 – $34,999",
                   "$35,000 – $44,999",
                   "$45,000 – $54,999",
                   "$55,000 – $64,999",
                   "$65,000 – $74,999",
                   "$20,000 and Over",
                   "Under $20,000",
                   "$75,000 - $99,999",
                   "$100,000 and Over"
)


# convert "missing" to NA and recode as factor
df <- df %>% 
  mutate(
    INDHHIN2 = ifelse(INDHHIN2 %in% c(77, 99, .), NA, INDHHIN2),
    Household_Income = factor(INDHHIN2,
                              levels = c(1:10, 12:15),
                              labels = income_levels,
                              ordered = TRUE)
  )
```


#### c. Tympanometric width measure distribution models
```{r}
# Clean the data first
df_model <- df %>%
  filter(
    !is.na(AUXTWIDR) 
    & !is.na(AUXTWIDL)
    & !is.na(Gender) 
    & !is.na(Citizenship) 
    & !is.na(Children_under_5) 
    & !is.na(Household_Income) 
    & AUXTWIDR > 0
  ) %>%
  # convert household income to numeric for continuous
  # using midpoint approach
  mutate(
    Children_under_5 = as.numeric(Children_under_5),
    Income_cont = case_when(
      Household_Income == "$0 - $4,999" ~ 2500,
      Household_Income == "$5,000 – $9,999" ~ 7500,
      Household_Income == "$10,000 – $14,999" ~ 12500,
      Household_Income == "$15,000 – $19,999" ~ 17500,
      Household_Income == "$20,000 – $24,999" ~ 22500,
      Household_Income == "$25,000 – $34,999" ~ 30000,
      Household_Income == "$35,000 – $44,999" ~ 40000,
      Household_Income == "$45,000 – $54,999" ~ 50000,
      Household_Income == "$55,000 – $64,999" ~ 60000,
      Household_Income == "$65,000 – $74,999" ~ 70000,
      Household_Income == "$20,000 and Over" ~ 50000,
      Household_Income == "Under $20,000" ~ 15000,
      Household_Income == "$75,000 - $99,999" ~ 87500,
      Household_Income == "$100,000 and Over" ~ 112500
    ) / 10000 # scale by 10,000 for better coefficient interpretation
  )
```


* Model 1R - Right ear: gender

```{r warning = FALSE}
model_1R <- glm(AUXTWIDR ~ Gender, 
                data = df_model,
                family = poisson(link = "log")) 
model_1R
```

* Model 2R - Right ear: gender, citizenship status (as categorical), number of children (as continuous), annual household income (as continuous)

```{r warning = FALSE}
model_2R <- glm(AUXTWIDR ~ Gender + Citizenship + Children_under_5 + Income_cont, 
                data = df_model,
                family = poisson(link = "log")) 
model_2R
```

* Model 1L - Left ear: gender

```{r warning = FALSE}
model_1L <- glm(AUXTWIDL ~ Gender, 
                data = df_model,
                family = poisson(link = "log")) 
model_1L
```

* Model 2L - Left ear: gender, citizenship status (as categorical), number of children (as continuous), annual household income (as continuous)

```{r warning = FALSE}
model_2L <- glm(AUXTWIDL ~ Gender + Citizenship + Children_under_5 + Income_cont, 
                data = df_model,
                family = poisson(link = "log")) 
model_2L
```

We will write a function to extract the model coefficients and statistics.

```{r}
#' Function to extract the model results
#'
#' @param model one of the four models above
#' @param model_name name of the models
#' 
extract_model_results <- function(model, model_name) {
  # get model coefficients
  coefs <- tidy(model, conf.int = TRUE, exponentiate = TRUE) %>%
    mutate(
      stats = sprintf("%.4f", model$coef),
      term = case_when(
        term == "(Intercept)" ~ "Intercept",
        term == "GenderF" ~ "Female (vs Male)",
        term == "CitizenshipNon-Citizen" ~ "Non-Citizen (vs Citizen)",
        term == "Children_under_5" ~ "Children Under 5",
        term == "Income_cont" ~ "Household Income ($10k)",
        TRUE ~ term
      )
    ) %>%
    select(term, stats)
  
  # get model statistics
  stats <- data.frame(
    term = c("N", "Pseudo-R2", "AIC"),
    stats = c(
      length(model$y),
      sprintf("%.4f", 1 - model$deviance / model$null.deviance),
      sprintf("%.1f", AIC(model))
    )
  )
  
  # combine coefficients and statistics
  bind_rows(coefs, stats) %>%
    mutate(model = model_name) %>%
    select(model, everything())
}
```

Extract results for all models

```{r}
results_1R <- extract_model_results(model_1R, "Model 1R")
results_2R <- extract_model_results(model_2R, "Model 2R")
results_1L <- extract_model_results(model_1L, "Model 1L")
results_2L <- extract_model_results(model_2L, "Model 2L")

# keep the results of all models in one table
all_results <- bind_rows(results_1R, results_2R, results_1L, results_2L)
```

Produce the table presenting the coefficients and model statistics

```{r}
# reshape to wide format
all <- all_results %>%
  pivot_wider(
    id_cols = term,
    names_from = model, 
    values_from = stats
  ) %>%
  # reorder terms logically
  mutate(order = case_when(
    term == "Intercept" ~ 1,
    term == "Female (vs Male)" ~ 2,
    term == "Non-Citizen (vs Citizen)" ~ 3,
    term == "Children Under 5" ~ 4,
    term == "Household Income ($10k)" ~ 5,
    term == "N" ~ 6,
    term == "Pseudo-R2" ~ 7,
    term == "AIC" ~ 8
  )) %>%
  arrange(order) %>%
  select(-order)

# create nice table
opts <- options(knitr.kable.NA = "-")
knitr::kable(
  all,
  col.names = c("Statistics", "Model 1R", "Model 2R", "Model 1L", "Model 2L"),
  caption = "Poisson Regression Results for Tympanometric Width") %>%
  kable_styling(bootstrap_options = "bordered",
                full_width = FALSE,
                position = "center")
```

#### d. From model 2L

We need to test whether there is a difference between males and females in terms of their incidence risk ratio (IRR).

Let $\beta_1$ be the coefficient `GenderF` which represents the log(IRR) of females comparing to males. The null and alternative hypothesis for the test are:

$H_0:$ $\beta_1 = 0$

$H_a:$ $\beta_1 \neq 0$

```{r}
summary(model_2L)$coef["GenderF", ]
```
We see that the p-value = $0.000229 < 0.001$, so there is very strong evidence against the null hypothesis. We support that there is a difference between males and females in terms of their incidence risk ratio given other co-variates stay constant. The $IRR = exp(0.013131) = 1.01321$, so Female  Females have wider left ears

Now we will test the predicted value of Tympanometric width measure of the left ear between females and males.

Let $p_F$ be the mean predicted value of Tympanometric width measure of the females' left ear, 
    $p_M$ be the mean predicted value of Tympanometric width measure of the males' left ear.

Our hypotheses are:

$H_0:$ $p_F - p_M = 0$

$H_a:$ $p_F - p_M \neq 0$

```{r align = c}
# predicted values
data_F <- df_model[df_model$Gender == "F", ]
data_M <- df_model[df_model$Gender == "M", ]

pred_F <- predict(model_2L, newdata = data_F, type = "response")
pred_M <- predict(model_2L, newdata = data_M, type = "response")

boxplot(pred_F, pred_M, names=c("M","F"))
c(mean(pred_F), mean(pred_M))

t.test(pred_F, pred_M)
```
Following our t-test, t-stat = $15.26$ and p-value = $2.2 \times 10^{-16} < 0.001$. We support the alternative hypothesis that the true difference in means predicted value of Tympanometric width measure of the left ear between females and males is not 0. The $95\%$ confidence interval is $[0.9653634, 1.2499999]$ so females tend to have larger left ear width.

## Problem 2: Sakila

```{r}
sakila <- dbConnect(RSQLite::SQLite(), "sakila_master.db")
dbListTables(sakila)

gg <- function(query) {
  dbGetQuery(sakila, query)
}
```

#### a. For each store, number of customers and percentage active

```{r}
# SQL then R operations
customer_r <- function() {
  # extract data frames
  store <- gg("
              SELECT store_id
              FROM store  
              ")
  customer <- gg("
                 SELECT store_id, customer_id, active
                 FROM customer
                 ")
  # merge in R
  customer_active <- left_join(store, customer, by = "store_id")
  
  # find number of customers and percentage active
  results <- customer_active %>% group_by(store_id) %>% 
    summarise(
      num_active = sum(active == 1, na.rm = TRUE),
      num_customer = n(), 
      percent_active = num_active/num_customer * 100
    ) %>%
    mutate(percent_active = round(percent_active, 2)) %>%
    ungroup()
  
  return(results[, c(1,3,4)])
}
customer_r()

# single SQL query
customer_sql <- function() {
  results <- gg("
                 SELECT s.store_id, 
                        COUNT(customer_id) as num_customer,
                        ROUND((SUM(CASE WHEN active = 1 THEN 1 ELSE 0 END) 
                             * 100.0 / COUNT(customer_id)), 2) AS percent_active
                 FROM store AS s 
                      LEFT JOIN customer AS c 
                           ON s.store_id = c.store_id
                      GROUP BY s.store_id
                ")
}
customer_sql()
```
We got the same results!

```{r}
# compare the time
microbenchmark(
  R = customer_r(),
  sQL = customer_sql()
)
```
Using only SQL is about $10$ times faster than manual R.


#### b. Generate a table identifying the names and country of each staff member

```{r}
# SQL then base R
staff_r <- function() {
  # extract data frames
  staff <- gg("
              SELECT first_name, last_name, address_id
              FROM staff
              ")
  address <- gg("
                SELECT address_id, city_id
                FROM address
                ")
  city <- gg("
             SELECT city_id, country_id
             FROM city
             ")
  country <- gg("
                SELECT country_id, country
                FROM country
                ")
  
  # merge in R
  staff_country <- staff %>%
    left_join(address, by = "address_id") %>%
    left_join(city, by = "city_id") %>%
    left_join(country, by = "country_id")
  
  # combine names
  staff_country$name <- paste(staff_country$first_name,
                              staff_country$last_name, 
                              sep = " ")
  results <- staff_country[, c("name", "country")]
  return(results)
}
staff_r()

# only SQL
staff_sql <- function() {
  results <- gg("
                SELECT CONCAT(first_name, ' ', last_name) AS name,
                       country
                FROM staff AS s
                     LEFT JOIN address AS a 
                          ON s.address_id = a.address_id
                     LEFT JOIN city AS ci 
                          ON ci.city_id = a.city_id
                     LEFT JOIN country as co 
                          ON co.country_id = ci.country_id
                ")
  return(results)
}
staff_sql()
```

We got the same results.

```{r}
microbenchmark(
  R = staff_r(),
  SQL = staff_sql()
)
```

One single SQL query is about $10$ times faster than SQL then R operations.

#### c. Identify the name(s) of the film(s) which was/were rented for the highest dollar value

```{r echo = FALSE}
# SQL + base R
film_r <- function() {
  # extract data frames
  film <- gg("
             SELECT film_id, title
             FROM film
             ")
  inventory <- gg("
                  SELECT inventory_id, film_id
                  FROM inventory
                  ")
  rental <- gg("
               SELECT rental_id, inventory_id
               FROM rental
               ")
  payment <- gg("
                SELECT rental_id, amount
                FROM payment
                ")
  
  # merge in R
  film_rent <- payment %>%
    left_join(rental, by = "rental_id") %>%
    left_join(inventory, by = "inventory_id") %>%
    left_join(film, by = "film_id") 
    
  # find the film with highest dollar value rented
  results <- film_rent %>% group_by(film_id, title) %>%
    summarize(total_revenue = sum(amount)) %>% 
    ungroup() %>%
    slice_max(total_revenue) %>%
    select(title, total_revenue)
 
  return(results)
}
film_r()

# one SQL query
film_sql <- function() {
  results <- gg("
                 SELECT title, MAX(total_revenue) AS total_revenue 
                 FROM (
                       SELECT title,
                              SUM(amount) AS total_revenue
                       FROM payment AS p 
                            LEFT JOIN rental AS r 
                                 ON r.rental_id = p.rental_id
                            LEFT JOIN inventory AS i
                                 ON r.inventory_id = i.inventory_id
                            LEFT JOIN film AS f
                                 ON i.film_id = f.film_id
                       GROUP BY f.film_id
                       )
                 ")
  
  return(results)
}
film_sql()
```

We got the same results that `TELEGRAPH VOYAGE` is the film with highest rental values.


```{r message = FALSE, warning = FALSE}
microbenchmark(
  R = film_r(),
  SQL = film_sql()
)
```
R is a little slower than SQL.

## Problem 3: Australian Records

```{r}
# import data to R
aus_data <- read.csv("au-500.csv")
head(aus_data)
# number of records
records <- nrow(aus_data)
```

#### a. Percentage of websites are .com

```{r}
web_dot_com <- grep("\\.com$", aus_data$web)
percent <- length(web_dot_com) / records * 100
cat("Percentage of websites are '.com' is ", percent, "%")
```
#### b. Most common domain name amongst email addresses

```{r}
# find everything from the start up to @ then replace it with ""
domains <- aus_data %>%
  mutate(domain = gsub(".*@", "", aus_data$email)) %>%
  count(domain, name = "count")

domains %>% slice_max(count)
```

The most common domain name amongst all email address is `hotmail.com`

#### c. Proportion of company names contain a non-alphabetic character

```{r}
# proportion of company names that contain special characters
# including ampersands
special_with_amp <- grep("[^a-zA-Z, \\s]", aus_data$company_name)

count_special_with_amp <- length(special_with_amp)
prop_with_amp <- count_special_with_amp / records * 100
cat("Proportion of company names contain a non-alphabetic character is", 
    round(prop_with_amp,2), "%\n")

# proportion of company names that contain special characters
# excluding ampersands
special_wo_amp <- grep("[^a-zA-Z, &\\s]", aus_data$company_name)

count_special_wo_amp <- length(special_wo_amp)
prop_wo_amp <- count_special_wo_amp / records * 100
cat("Proportion of company names contain a non-alphabetic character excluding
ampersands is", round(prop_wo_amp,2), "%")
```

#### d. Make all phone numbers written like cell phones

```{r}
# delete all - in the numbers
numbers <- gsub("-", "", aus_data$phone1)

# add - at correct positions
phone1_cell <- gsub("^([0-9]{4})([0-9]{3})", "\\1-\\2-", numbers)

cat("First 10 numbers of landlines: \n")
head(phone1_cell, 10)

cat("First 10 numbers of cell phones: \n")
head(aus_data$phone2, 10)
```
#### e. Histogram of the log of the apartment numbers for all addresses

```{r}
# pattern with apt number at the end
apt_num <- regmatches(aus_data$address, regexpr("(\\d+)$", aus_data$address))
apt_num <- as.numeric(apt_num)


# create data frame for histogram
apt_data <- data.frame(
  apartment_number = apt_num,
  log_apartment = log(apt_num)
)

histogram <- ggplot(data = apt_data, mapping = aes(log_apartment)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = "log of apartment numbers")

histogram
```

#### f. Benford's law

```{r, align = c}
apt_first_digits <- benford(apt_num, number.of.digits = 1)
plot(apt_first_digits)
chisq(apt_first_digits)
```

The distribution of the leading digits of the apartment numbers significantly deviates from Benford's Law with the significant result from p-value of $1.67 \times 10^{-10}$. This can not be used as real data.


































